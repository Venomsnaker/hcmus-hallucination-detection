{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec6982c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import json\n",
    "from collections import Counter\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import Qwen3VLForConditionalGeneration, AutoProcessor\n",
    "\n",
    "from egh_vlm.hallucination_dataset import HallucinationDataset, PairedHallucinationDataset, load_features, split_stratified, paired_hallucination_collate_fn\n",
    "from egh_vlm.hallucination_detector import PairedDetectorModule\n",
    "from egh_vlm.training import train_paired_detector, eval_paired_detector\n",
    "from egh_vlm.utils import ModelBundle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6d4f0b",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4987d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset_path', type=str, default='../data/phd/prototype/phd_sample_qwen3_vl_2b_balanced.json')\n",
    "parser.add_argument('--img_folder_path', type=str, default='../data/phd/images')\n",
    "parser.add_argument('--features_question_only_path', type=str, default='../data/phd/prototype/features_question_only.pt')\n",
    "parser.add_argument('--features_image_only_path', type=str, default='../data/phd/prototype/features_image_only.pt')\n",
    "parser.add_argument('--features_full_path', type=str, default='../data/phd/prototype/features_full.pt')\n",
    "parser.add_argument('--detector_path', type=str, default='../data/phd/prototype/detector_paired.pt')\n",
    "parser.add_argument('--model_name', type=str, default='Qwen/Qwen3-VL-2B-Instruct')\n",
    "parser.add_argument('--train_ratio', type=float, default=0.7)\n",
    "args = parser.parse_args('')\n",
    "config = vars(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3a94c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of question only features: 3770\n",
      "Length of image only features: 3774\n",
      "Length of full features: 3774\n",
      "Hidden size: 2048\n"
     ]
    }
   ],
   "source": [
    "def get_features(save_path, sample_size=None):\n",
    "    if os.path.isfile(save_path):\n",
    "        features = load_features(save_path)\n",
    "        return features, features.embs[0].size(-1) if len(features) > 0 else 0\n",
    "    else:\n",
    "        return HallucinationDataset(), 0\n",
    "\n",
    "features_question_only, hidden_size_question_only = get_features(\n",
    "    save_path=args.features_question_only_path)\n",
    "features_image_only, hidden_size_image_only = get_features(\n",
    "    save_path=args.features_image_only_path)\n",
    "features_full, hidden_size_full = get_features(\n",
    "    save_path=args.features_full_path)\n",
    "\n",
    "assert hidden_size_question_only == hidden_size_image_only, \"Hidden sizes of question-only and image-only features must match\"\n",
    "hidden_size = hidden_size_question_only\n",
    "\n",
    "print('Length of question only features:', len(features_question_only))\n",
    "print('Length of image only features:', len(features_image_only))\n",
    "print('Length of full features:', len(features_full))\n",
    "print('Hidden size:', hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69d19a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of paired features: 3770\n"
     ]
    }
   ],
   "source": [
    "features_paired = PairedHallucinationDataset()\n",
    "\n",
    "for id in features_question_only.ids:\n",
    "    feature_image_only = features_image_only.get_by_id(id)\n",
    "    feature_question_only = features_question_only.get_by_id(id)\n",
    "    assert feature_image_only[3] == feature_question_only[3]\n",
    "    features_paired.add_item(\n",
    "        id,\n",
    "        [\n",
    "            [feature_image_only[1], feature_image_only[2]],\n",
    "            [feature_question_only[1], feature_question_only[2]],\n",
    "        ],\n",
    "        feature_image_only[3]\n",
    "    )\n",
    "print('Length of paired features:', len(features_paired))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50af5044",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = split_stratified(features_paired, train_ratio=args.train_ratio, random_state=42)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    collate_fn=paired_hallucination_collate_fn,\n",
    "    shuffle=True,\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=16,\n",
    "    collate_fn=paired_hallucination_collate_fn,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1b56553",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 30\n",
    "lr = 1e-4\n",
    "\n",
    "log_save_path = f'../data/logs/egh_vlm_paired_log.txt'\n",
    "logging.basicConfig(filename=log_save_path, level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "result = {\n",
    "    'train_ratio': args.train_ratio,\n",
    "    'epoch': epoch,\n",
    "    'lr': lr,\n",
    "    'acc': {\n",
    "        'value': 0.0,\n",
    "        'epoch': -1\n",
    "    },\n",
    "    'f1': {\n",
    "        'value': 0.0,\n",
    "        'epoch': -1\n",
    "    },\n",
    "    'pr_auc': {\n",
    "        'value': 0.0,\n",
    "        'epoch': -1\n",
    "    }\n",
    "}\n",
    "\n",
    "detector = PairedDetectorModule(hidden_size, hidden_size, 1)\n",
    "loss_fn = nn.BCELoss()\n",
    "optim = torch.optim.Adam(detector.parameters(), lr=lr)\n",
    "\n",
    "for i in range(epoch):\n",
    "    total_loss = train_paired_detector(detector, loss_fn, optim, train_dataloader)\n",
    "    acc, f1, pr_auc = eval_paired_detector(detector, val_dataloader)\n",
    "    \n",
    "    logging.debug(f'Epoch [{i+1}/{epoch}], Loss: {total_loss:.4f}')\n",
    "    logging.debug(f'Epoch [{i+1}/{epoch}], ACC: {acc:.4f}, F1: {f1:.4f}, PR-AUC:{pr_auc:.4f}\\n')\n",
    "    if acc > result['acc']['value']:\n",
    "        result['acc']['value'] = acc\n",
    "        result['acc']['epoch'] = i + 1\n",
    "    if f1 > result['f1']['value']:\n",
    "        result['f1']['value'] = f1\n",
    "        result['f1']['epoch'] = i + 1\n",
    "    if pr_auc > result['pr_auc']['value']:\n",
    "        result['pr_auc']['value'] = pr_auc\n",
    "        result['pr_auc']['epoch'] = i + 1\n",
    "    if total_loss < 1e-4:\n",
    "        break\n",
    "logging.debug(f'Eval ACC: {result[\"acc\"][\"value\"]:.4f} at epoch {result[\"acc\"][\"epoch\"]}')\n",
    "logging.debug(f'Eval F1: {result[\"f1\"][\"value\"]:.4f} at epoch {result[\"f1\"][\"epoch\"]}')\n",
    "logging.debug(f'Eval PR-AUC: {result[\"pr_auc\"][\"value\"]:.4f} at epoch {result[\"pr_auc\"][\"epoch\"]}')\n",
    "\n",
    "# Clean up logger handlers\n",
    "logger = logging.getLogger()\n",
    "for handler in logger.handlers[:]:\n",
    "    handler.close()\n",
    "    logger.removeHandler(handler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hcmus-hallucination-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
