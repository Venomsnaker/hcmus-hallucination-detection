{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "835fdcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def343f8",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c855e877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load the Hallusion Bench dataset with: 16844 samples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "task",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "yes_question",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "no_question",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "context",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "image_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "hitem",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "subject",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "gt",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "66f62cd1-de46-4d80-ba72-35af9ddbd93e",
       "rows": [
        [
         "0",
         "counting",
         "Are there three couches in the image?",
         "Are there 2 couches in the image?",
         "{'icc': 'In a cozy living room setting, two couches are arranged around a television, creating a welcoming atmosphere for relaxation and entertainment. A man stands in front of the television, positioned near a large window, highlighting the natural light that fills the space. Nearby, a person is actively engaged in a game with the Wii remote control, adding a lively dynamic to the scene.', 'sec': \"The living room, designed for comfort during game nights, typically accommodates two couches. This inviting space encourages relaxation and social interaction as friends gather to enjoy their favorite games. With a large television positioned conveniently, it's the perfect setup for memorable evenings filled with fun and laughter.\"}",
         "000000262207",
         "2",
         "couches",
         "three"
        ],
        [
         "1",
         "sentiment",
         "Is the cat looking sad in the image?",
         "Is the cat content in the image?",
         "{'icc': 'The cat in the image appears to be content, comfortably nestled in a vibrant red basket. This scene captures a serene moment, with the white and gray cat resting peacefully, an image of tranquility amid its surroundings. Nearby, other items hint at a cozy space where this feline can regularly unwind in its favorite spot.', 'sec': 'The cat is usually found relaxed and content in its red basket, appreciating the cozy surroundings. Its white and gray fur blends beautifully with the warm hue of the basket, making it a perfect spot for naps. Often surrounded by other items in the room, this serene feline enjoys the comfort of its dedicated space.'}",
         "000000354493",
         "content",
         "cat",
         "sad"
        ],
        [
         "2",
         "counting",
         "Are there four people in the image?",
         "Are there exactly three people in the image?",
         "{'icc': 'In the image, there are exactly three people engaged in playing baseball on a field. A group of young men appear to be actively participating in a baseball game together, showcasing their skills and teamwork.', 'sec': 'In baseball games, the action is often centered around the trio of the pitcher, batter, and catcher. This setup allows for intense focus and excitement as these three players engage in a dynamic exchange that drives the game forward, amidst a larger group of enthusiastic players on the field.'}",
         "000000102532",
         "3",
         "people",
         "4"
        ],
        [
         "3",
         "sentiment",
         "Is the boy appearing happy in the image?",
         "Is the boy displaying a mischievous expression in the image?",
         "{'icc': 'In a delightful scene, the boy is displaying a mischievous expression in the image as he indulges in donut holes while sitting at the dinner table. With a large smile on his face, the young child looks enthused over the dessert spread out before him, clearly enjoying the experience. Clutching a blue plate filled with treats, he captures the joy of simple pleasures in a candid moment.', 'sec': 'The boy is often seen with a mischievous expression when indulging in his favorite treats, especially donuts. His enthusiasm is unmistakable as he enjoys his dessert at the dinner table, showcasing a cheerful demeanor that lights up the room. With a bright smile, he savors each bite, making the moment all the more delightful.'}",
         "000000099810",
         "mischievous",
         "boy",
         "happy"
        ],
        [
         "4",
         "positional",
         "Is there an object located two hundred and thirteen units in front of the bike in the image?",
         "Is there anything in front of the bike in the image?",
         "{'icc': 'In the thrilling moment captured in the photo, a black and yellow bike navigates a tight turn on the track, revealing a sense of speed and precision as it leans into the curve. Meanwhile, another image features a rider in a blue jacket controlling a black motorcycle, expertly rounding the bend on a curvy road. The dynamic nature of motorcycle racing is vividly illustrated through these snapshots, showcasing the skill required to maneuver through challenging terrains.', 'sec': 'The track is usually surrounded by various signs and spectators, creating a bustling atmosphere right in front of the racing bike. In this thrilling race, a rider can be seen leaning into a very tight turn, showcasing skill and precision as they navigate the sharp curve. The excitement is palpable as the motorcycle rounds the bend, emphasizing the dynamic nature of competitive racing.'}",
         "000000049683",
         "0",
         "front of the bike",
         "two hundred and thirteen"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>yes_question</th>\n",
       "      <th>no_question</th>\n",
       "      <th>context</th>\n",
       "      <th>image_id</th>\n",
       "      <th>hitem</th>\n",
       "      <th>subject</th>\n",
       "      <th>gt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>counting</td>\n",
       "      <td>Are there three couches in the image?</td>\n",
       "      <td>Are there 2 couches in the image?</td>\n",
       "      <td>{'icc': 'In a cozy living room setting, two co...</td>\n",
       "      <td>000000262207</td>\n",
       "      <td>2</td>\n",
       "      <td>couches</td>\n",
       "      <td>three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sentiment</td>\n",
       "      <td>Is the cat looking sad in the image?</td>\n",
       "      <td>Is the cat content in the image?</td>\n",
       "      <td>{'icc': 'The cat in the image appears to be co...</td>\n",
       "      <td>000000354493</td>\n",
       "      <td>content</td>\n",
       "      <td>cat</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>counting</td>\n",
       "      <td>Are there four people in the image?</td>\n",
       "      <td>Are there exactly three people in the image?</td>\n",
       "      <td>{'icc': 'In the image, there are exactly three...</td>\n",
       "      <td>000000102532</td>\n",
       "      <td>3</td>\n",
       "      <td>people</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sentiment</td>\n",
       "      <td>Is the boy appearing happy in the image?</td>\n",
       "      <td>Is the boy displaying a mischievous expression...</td>\n",
       "      <td>{'icc': 'In a delightful scene, the boy is dis...</td>\n",
       "      <td>000000099810</td>\n",
       "      <td>mischievous</td>\n",
       "      <td>boy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positional</td>\n",
       "      <td>Is there an object located two hundred and thi...</td>\n",
       "      <td>Is there anything in front of the bike in the ...</td>\n",
       "      <td>{'icc': 'In the thrilling moment captured in t...</td>\n",
       "      <td>000000049683</td>\n",
       "      <td>0</td>\n",
       "      <td>front of the bike</td>\n",
       "      <td>two hundred and thirteen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         task                                       yes_question  \\\n",
       "0    counting              Are there three couches in the image?   \n",
       "1   sentiment               Is the cat looking sad in the image?   \n",
       "2    counting                Are there four people in the image?   \n",
       "3   sentiment           Is the boy appearing happy in the image?   \n",
       "4  positional  Is there an object located two hundred and thi...   \n",
       "\n",
       "                                         no_question  \\\n",
       "0                  Are there 2 couches in the image?   \n",
       "1                   Is the cat content in the image?   \n",
       "2       Are there exactly three people in the image?   \n",
       "3  Is the boy displaying a mischievous expression...   \n",
       "4  Is there anything in front of the bike in the ...   \n",
       "\n",
       "                                             context      image_id  \\\n",
       "0  {'icc': 'In a cozy living room setting, two co...  000000262207   \n",
       "1  {'icc': 'The cat in the image appears to be co...  000000354493   \n",
       "2  {'icc': 'In the image, there are exactly three...  000000102532   \n",
       "3  {'icc': 'In a delightful scene, the boy is dis...  000000099810   \n",
       "4  {'icc': 'In the thrilling moment captured in t...  000000049683   \n",
       "\n",
       "         hitem            subject                        gt  \n",
       "0            2            couches                     three  \n",
       "1      content                cat                       sad  \n",
       "2            3             people                         4  \n",
       "3  mischievous                boy                     happy  \n",
       "4            0  front of the bike  two hundred and thirteen  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = '../data/phd/phd.json'\n",
    "save_path = '../data/phd/prototype/phd_sample.json'\n",
    "sample_size = None\n",
    "\n",
    "with open(dataset_path, 'r', encoding='utf-8') as f:\n",
    "    dataset = json.load(f)\n",
    "if sample_size is not None and len(dataset) > sample_size:\n",
    "    dataset = dataset[:sample_size]\n",
    "\n",
    "df = pd.DataFrame(dataset)\n",
    "\n",
    "# Drop css_description \n",
    "df = df[df['ccs_description'].isna()]\n",
    "df = df.drop(columns=['ccs_description'])\n",
    "\n",
    "print(f'Successfully load the Hallusion Bench dataset with: {len(df)} samples.')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96586298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "task",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "8c993f3b-9694-426f-9c21-b47b9f81e7e4",
       "rows": [
        [
         "object",
         "5736"
        ],
        [
         "attribute",
         "3997"
        ],
        [
         "counting",
         "2844"
        ],
        [
         "positional",
         "2492"
        ],
        [
         "sentiment",
         "1775"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 5
       }
      },
      "text/plain": [
       "task\n",
       "object        5736\n",
       "attribute     3997\n",
       "counting      2844\n",
       "positional    2492\n",
       "sentiment     1775\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_counts = df['task'].value_counts()\n",
    "task_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d44baec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes answer unique count: 6200\n",
      "No answer unique count: 8326\n"
     ]
    }
   ],
   "source": [
    "yes_answer_nunique = df['yes_question'].nunique()\n",
    "no_answer_nunique = df['no_question'].nunique()\n",
    "\n",
    "print('Yes answer unique count:', yes_answer_nunique)\n",
    "print('No answer unique count:', no_answer_nunique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d160faca",
   "metadata": {},
   "source": [
    "## Dataset Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5dc574f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_and_balance(group, sample_size=1500, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    n_sample = min(sample_size, len(group))\n",
    "    \n",
    "    # Create unique identifier excluding unhashable columns\n",
    "    hashable_cols = ['yes_question', 'no_question']\n",
    "    group['unique_id'] = range(len(group))  # Temporary unique ID\n",
    "    \n",
    "    # Sample maximizing unique yes/no question pairs\n",
    "    unique_pairs = group.drop_duplicates(subset=hashable_cols)\n",
    "    n_unique = min(n_sample, len(unique_pairs))\n",
    "    group_sampled = unique_pairs.sample(n=n_unique, random_state=seed)\n",
    "    \n",
    "    # Fill remaining if needed (no drop_duplicates to avoid dict error)\n",
    "    remaining_needed = n_sample - len(group_sampled)\n",
    "    if remaining_needed > 0:\n",
    "        additional = group.sample(n=remaining_needed, random_state=seed)\n",
    "        group_sampled = pd.concat([group_sampled, additional]).reset_index(drop=True)\n",
    "    group_sampled = group_sampled.drop(columns=['unique_id'], errors='ignore')\n",
    "    \n",
    "    # Balance yes/no labels\n",
    "    n = len(group_sampled)\n",
    "    yes_indices = np.random.choice(group_sampled.index, size=n//2, replace=False)\n",
    "    no_indices = np.setdiff1d(group_sampled.index, yes_indices)\n",
    "    \n",
    "    group_sampled.loc[yes_indices, 'question'] = group_sampled.loc[yes_indices, 'yes_question']\n",
    "    group_sampled.loc[no_indices, 'question'] = group_sampled.loc[no_indices, 'no_question']\n",
    "    group_sampled['label'] = 0\n",
    "    group_sampled.loc[yes_indices, 'label'] = 1\n",
    "    \n",
    "    return group_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a5b2711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (7500, 10)\n",
      "Number of unique questions: 5136\n",
      "Number of unique yes questions: 4154\n",
      "Number of unique no questoins: 5440\n",
      "\n",
      " label\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      " task\n",
      "attribute     0.2\n",
      "counting      0.2\n",
      "object        0.2\n",
      "positional    0.2\n",
      "sentiment     0.2\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      " label         0    1\n",
      "task                \n",
      "attribute   0.5  0.5\n",
      "counting    0.5  0.5\n",
      "object      0.5  0.5\n",
      "positional  0.5  0.5\n",
      "sentiment   0.5  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_23976\\1680852295.py:3: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(sample_and_balance)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "task",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "yes_question",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "no_question",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "context",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "image_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "hitem",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "subject",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "gt",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "question",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "7d273e0b-48ff-4342-b91f-85e7dd7f1fd6",
       "rows": [
        [
         "0",
         "attribute",
         "Are the shirts in the image white?",
         "Is any of the shirts in the image gray?",
         "{'icc': 'In a lively living room setting, two friends are deeply engaged in a video game, each holding a Wii controller in hand. Notably, some of the shirts they are wearing are gray, adding a casual touch to their gaming session. This dynamic scene captures the joy of remote play, showcasing the camaraderie between the two as they enjoy their time together.', 'sec': 'During a lively gaming session, one of the friends, often recognized by his gray shirt, engages in a competitive video game with his buddy. Their enthusiasm is palpable as they share laughs and strategy, clearly relishing the time spent together. The atmosphere is filled with camaraderie, showcasing the joy of friendship through gaming.'}",
         "000000452966",
         "gray",
         "shirts",
         "white",
         "Is any of the shirts in the image gray?",
         "0"
        ],
        [
         "1",
         "attribute",
         "Is the monitor screen rectangular in shape?",
         "Is the monitor screen circular in shape?",
         "{'icc': 'The monitor screen is circular in shape, providing a unique aesthetic in a modern workspace. Image of a black cat laying on a white laptop captures the essence of a cozy environment, while a cat is watching the clouds on the monitor, adding a touch of whimsy to the scene. Nearby, a black cat sits next to a couple of monitors, creating a charming tableau that blends technology and feline companionship.', 'sec': 'Circular monitor screens are favored by many cat owners due to their unique design that easily captures the attention of curious felines. This often leads to playful interactions, as cats find themselves drawn to the bright and dynamic visuals displayed on the screens. The presence of these monitors not only enhances the aesthetic of a workspace but also becomes a source of entertainment for our furry companions.'}",
         "000000198641",
         "circular",
         "monitor screen",
         "rectangle",
         "Is the monitor screen circular in shape?",
         "0"
        ],
        [
         "2",
         "attribute",
         "Is the vase made of the same material as the floor in the image?",
         "Is the floor made of acrylic in the image?",
         "{'icc': 'The floor in the image is made of acrylic, providing a sleek and modern aesthetic. Accompanying this striking feature is a glass bottle on a red surface with a matching backdrop, creating a bold visual contrast. Nearby, a fancy colorful bottle and a small glass vial rest on a tablecloth, further enhancing the vibrant arrangement of items displayed.', 'sec': \"The display features a striking acrylic surface that amplifies the vibrant colors of the decorative elements showcased above. This innovative approach highlights the careful arrangement of the items, creating an eye-catching presentation. The combination of vivid hues against the polished background draws viewers' attention, enhancing their overall experience.\"}",
         "000000494991",
         "acrylic",
         "floor",
         "vase",
         "Is the vase made of the same material as the floor in the image?",
         "1"
        ],
        [
         "3",
         "attribute",
         "Is the woman wearing black in the image?",
         "Is the woman wearing white in the image?",
         "{'icc': \"The woman in the image is wearing white, adding a touch of elegance to the lively atmosphere of the gathering. A group of people sit and stand in a circle, holding drinks and engaging in animated conversations in the cozy living room. The scene captures the essence of friendship and camaraderie as they enjoy each other's company.\", 'sec': \"Social gatherings often showcase a diverse range of attire among guests. In these settings, it's common to spot a standout figure dressed in white, drawing attention amid the crowd. Conversations flow as individuals engage with one another over drinks in a lively atmosphere.\"}",
         "000000010966",
         "white",
         "woman",
         "black",
         "Is the woman wearing black in the image?",
         "1"
        ],
        [
         "4",
         "attribute",
         "Is the back wall made of brick in the image?",
         "Is the back wall made of concrete in the image?",
         "{'icc': 'In a recent event, two men took the stage, delivering a compelling speech in front of an engaged crowd. The backdrop of the stage featured a striking concrete wall, which framed the scene where one of the men was holding a remote while standing confidently in front of a large screen displaying their presentation. This dynamic atmosphere was complemented by a couple of other attendees in the room who were actively participating with a remote of their own.', 'sec': 'In many venues, the back wall is typically constructed from concrete, which plays a crucial role in ensuring sound stability during presentations. This acoustic design often complements the presence of speakers who engage with the audience, enhancing the overall experience of the event. The integration of technology, like remote controls, allows for seamless transitions and interaction with visual elements displayed on screen.'}",
         "000000050148",
         "Concrete",
         "back wall",
         "brick",
         "Is the back wall made of concrete in the image?",
         "0"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>yes_question</th>\n",
       "      <th>no_question</th>\n",
       "      <th>context</th>\n",
       "      <th>image_id</th>\n",
       "      <th>hitem</th>\n",
       "      <th>subject</th>\n",
       "      <th>gt</th>\n",
       "      <th>question</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>attribute</td>\n",
       "      <td>Are the shirts in the image white?</td>\n",
       "      <td>Is any of the shirts in the image gray?</td>\n",
       "      <td>{'icc': 'In a lively living room setting, two ...</td>\n",
       "      <td>000000452966</td>\n",
       "      <td>gray</td>\n",
       "      <td>shirts</td>\n",
       "      <td>white</td>\n",
       "      <td>Is any of the shirts in the image gray?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attribute</td>\n",
       "      <td>Is the monitor screen rectangular in shape?</td>\n",
       "      <td>Is the monitor screen circular in shape?</td>\n",
       "      <td>{'icc': 'The monitor screen is circular in sha...</td>\n",
       "      <td>000000198641</td>\n",
       "      <td>circular</td>\n",
       "      <td>monitor screen</td>\n",
       "      <td>rectangle</td>\n",
       "      <td>Is the monitor screen circular in shape?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attribute</td>\n",
       "      <td>Is the vase made of the same material as the f...</td>\n",
       "      <td>Is the floor made of acrylic in the image?</td>\n",
       "      <td>{'icc': 'The floor in the image is made of acr...</td>\n",
       "      <td>000000494991</td>\n",
       "      <td>acrylic</td>\n",
       "      <td>floor</td>\n",
       "      <td>vase</td>\n",
       "      <td>Is the vase made of the same material as the f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attribute</td>\n",
       "      <td>Is the woman wearing black in the image?</td>\n",
       "      <td>Is the woman wearing white in the image?</td>\n",
       "      <td>{'icc': 'The woman in the image is wearing whi...</td>\n",
       "      <td>000000010966</td>\n",
       "      <td>white</td>\n",
       "      <td>woman</td>\n",
       "      <td>black</td>\n",
       "      <td>Is the woman wearing black in the image?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>attribute</td>\n",
       "      <td>Is the back wall made of brick in the image?</td>\n",
       "      <td>Is the back wall made of concrete in the image?</td>\n",
       "      <td>{'icc': 'In a recent event, two men took the s...</td>\n",
       "      <td>000000050148</td>\n",
       "      <td>Concrete</td>\n",
       "      <td>back wall</td>\n",
       "      <td>brick</td>\n",
       "      <td>Is the back wall made of concrete in the image?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        task                                       yes_question  \\\n",
       "0  attribute                 Are the shirts in the image white?   \n",
       "1  attribute        Is the monitor screen rectangular in shape?   \n",
       "2  attribute  Is the vase made of the same material as the f...   \n",
       "3  attribute           Is the woman wearing black in the image?   \n",
       "4  attribute       Is the back wall made of brick in the image?   \n",
       "\n",
       "                                       no_question  \\\n",
       "0          Is any of the shirts in the image gray?   \n",
       "1         Is the monitor screen circular in shape?   \n",
       "2       Is the floor made of acrylic in the image?   \n",
       "3         Is the woman wearing white in the image?   \n",
       "4  Is the back wall made of concrete in the image?   \n",
       "\n",
       "                                             context      image_id     hitem  \\\n",
       "0  {'icc': 'In a lively living room setting, two ...  000000452966      gray   \n",
       "1  {'icc': 'The monitor screen is circular in sha...  000000198641  circular   \n",
       "2  {'icc': 'The floor in the image is made of acr...  000000494991   acrylic   \n",
       "3  {'icc': 'The woman in the image is wearing whi...  000000010966     white   \n",
       "4  {'icc': 'In a recent event, two men took the s...  000000050148  Concrete   \n",
       "\n",
       "          subject         gt  \\\n",
       "0          shirts      white   \n",
       "1  monitor screen  rectangle   \n",
       "2           floor       vase   \n",
       "3           woman      black   \n",
       "4       back wall      brick   \n",
       "\n",
       "                                            question  label  \n",
       "0            Is any of the shirts in the image gray?      0  \n",
       "1           Is the monitor screen circular in shape?      0  \n",
       "2  Is the vase made of the same material as the f...      1  \n",
       "3           Is the woman wearing black in the image?      1  \n",
       "4    Is the back wall made of concrete in the image?      0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample = (df\n",
    "             .groupby('task', group_keys=False)\n",
    "             .apply(sample_and_balance)\n",
    "             .reset_index(drop=True))\n",
    "\n",
    "print(f'Shape: {df_sample.shape}')\n",
    "print(f'Number of unique questions: {df_sample['question'].nunique()}')\n",
    "print(f'Number of unique yes questions: {df_sample['yes_question'].nunique()}')\n",
    "print(f'Number of unique no questoins: {df_sample['no_question'].nunique()}')\n",
    "print('\\n', df_sample['label'].value_counts(normalize=True).round(3))\n",
    "print('\\n', df_sample['task'].value_counts(normalize=True).round(3))\n",
    "print('\\n', df_sample.groupby('task')['label'].value_counts(normalize=True).round(3).unstack(fill_value=0))\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "596cfc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_sample.reset_index().rename(columns={'index': 'id'})\n",
    "output = df_sample.to_dict('records')\n",
    "\n",
    "with open(save_path, 'w') as f:\n",
    "    json.dump(output, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hcmus-hallucination-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
