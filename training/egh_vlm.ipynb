{
  "cells": [
    {
      "metadata": {
        "id": "20182471916228d3"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, random_split, Dataset\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_recall_curve, auc\n",
        "from transformers import Qwen3VLForConditionalGeneration, AutoProcessor\n",
        "\n",
        "import argparse\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import gc"
      ],
      "id": "20182471916228d3"
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bbea726d9b826e1",
        "outputId": "adc81a4a-3374-450a-fcc5-5001145ebf58"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/egh_vlm.zip\n",
            "   creating: egh_vlm/\n",
            "  inflating: egh_vlm/dataset.json    \n",
            "   creating: egh_vlm/images/\n",
            "  inflating: egh_vlm/images/001.jpg  \n",
            "  inflating: egh_vlm/images/002.jpg  \n"
          ]
        }
      ],
      "execution_count": null,
      "source": [
        "#!unzip /content/egh_vlm.zip"
      ],
      "id": "8bbea726d9b826e1"
    },
    {
      "metadata": {
        "id": "3abdaa96c51680c8"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "def extract_features(\n",
        "        query: str, image_path: str, answer: str, model, processor, device\n",
        "):\n",
        "    #region Get inputs\n",
        "    # image + answer\n",
        "    i_messages = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"image\", \"image\": image_path},\n",
        "            ],\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": [{\"type\": \"text\", \"text\": answer}],\n",
        "        }\n",
        "    ]\n",
        "    i_inputs = processor.apply_chat_template(\n",
        "        i_messages,\n",
        "        tokenize=True,\n",
        "        add_generation_prompt=False,\n",
        "        return_dict=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    i_inputs = {k: v.to(device) for k, v in i_inputs.items()}\n",
        "\n",
        "    # query + answer\n",
        "    q_messages = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\": query},\n",
        "            ],\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": [{\"type\": \"text\", \"text\": answer}],\n",
        "        }\n",
        "    ]\n",
        "    q_inputs = processor.apply_chat_template(\n",
        "        q_messages,\n",
        "        tokenize=True,\n",
        "        add_generation_prompt=False,\n",
        "        return_dict=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    q_inputs = {k: v.to(device) for k, v in q_inputs.items()}\n",
        "\n",
        "\n",
        "    # answer\n",
        "    a_messages = [\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": [{\"type\": \"text\", \"text\": answer}],\n",
        "        }\n",
        "    ]\n",
        "    a_inputs = processor.apply_chat_template(\n",
        "        a_messages,\n",
        "        tokenize=True,\n",
        "        add_generation_prompt=False,\n",
        "        return_dict=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    a_inputs = {k: v.to(device) for k, v in a_inputs.items()}\n",
        "    # endregion\n",
        "\n",
        "    with torch.set_grad_enabled(True):\n",
        "        model.eval()\n",
        "\n",
        "        q_output = model(**q_inputs, output_hidden_states=True)\n",
        "        i_output = model(**i_inputs, output_hidden_states=True)\n",
        "        a_output = model(**a_inputs, output_hidden_states=True)\n",
        "\n",
        "        q_length = q_inputs[\"input_ids\"].shape[1]\n",
        "        i_length = i_inputs[\"input_ids\"].shape[1]\n",
        "        a_length = a_inputs[\"input_ids\"].shape[1]\n",
        "\n",
        "        # Extract answer probs (slice after context)\n",
        "        q_prob = q_output.logits[0, q_length - (a_length - 1):, :]\n",
        "        i_prob = i_output.logits[0, i_length - (a_length - 1):, :]\n",
        "        a_prob = a_output.logits[0, 1:, :]\n",
        "\n",
        "        # Extract last hidden states (embeddings)\n",
        "        q_vector = q_output.hidden_states[-1]\n",
        "        i_vector = i_output.hidden_states[-1]\n",
        "        a_vector = a_output.hidden_states[-1]\n",
        "\n",
        "        a_embedding = a_vector[0, 1:, :]\n",
        "\n",
        "        # Question+answer embedding & gradient\n",
        "        qa_kl_divergence = torch.sum(\n",
        "            a_prob.softmax(dim=-1) * (a_prob.softmax(dim=-1).log() - torch.log_softmax(q_prob, dim=-1))\n",
        "        )\n",
        "        qa_gradient = torch.autograd.grad(\n",
        "            outputs=qa_kl_divergence, inputs=a_vector, create_graph=False, retain_graph=True,\n",
        "        )[0][0, 1:, :]\n",
        "\n",
        "        q_embedding = q_vector[0, q_length - (a_length - 1):, :]\n",
        "        qa_embedding = q_embedding - a_embedding\n",
        "\n",
        "        # Image+answer embedding & gradient\n",
        "        ia_kl_divergence = torch.sum(\n",
        "            a_prob.softmax(dim=-1) * (a_prob.softmax(dim=-1).log() - torch.log_softmax(i_prob, dim=-1))\n",
        "        )\n",
        "        ia_gradient = torch.autograd.grad(\n",
        "            outputs=ia_kl_divergence, inputs=a_vector, create_graph=False, retain_graph=True,\n",
        "        )[0][0, 1:, :]\n",
        "\n",
        "        i_embedding = i_vector[0, i_length - (a_length - 1):, :]\n",
        "        ia_embedding = i_embedding - a_embedding\n",
        "    return (\n",
        "        qa_embedding.detach().float().to(\"cpu\"),\n",
        "        qa_gradient.detach().float().to(\"cpu\"),\n",
        "        ia_embedding.detach().float().to(\"cpu\"),\n",
        "        ia_gradient.detach().float().to(\"cpu\"))\n",
        "\n",
        "def batch_extract_features(data_list, model, processor, device):\n",
        "    qa_embeddings = []\n",
        "    qa_gradients = []\n",
        "    ia_embeddings = []\n",
        "    ia_gradients = []\n",
        "\n",
        "    for data in tqdm(data_list, desc=\"Extract features:\"):\n",
        "        qa_embedding, qa_gradient, ia_embedding, ia_gradient = extract_features(\n",
        "            query = data['query'],\n",
        "            image_path= data['image_path'],\n",
        "            answer = data['answer'],\n",
        "            model=model,\n",
        "            processor=processor,\n",
        "            device=device\n",
        "        )\n",
        "        qa_embeddings.append(qa_embedding)\n",
        "        qa_gradients.append(qa_gradient)\n",
        "        ia_embeddings.append(ia_embedding)\n",
        "        ia_gradients.append(ia_gradient)\n",
        "\n",
        "        # Clear CUDA cache periodically\n",
        "        if len(qa_embeddings) % 10 == 0:\n",
        "            gc.collect()\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "    return qa_embeddings, qa_gradients, ia_embeddings, ia_gradients"
      ],
      "id": "3abdaa96c51680c8"
    },
    {
      "metadata": {
        "id": "67b4e544a0644a9d"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "def get_mean(input_list):\n",
        "    temp = []\n",
        "    for x in input_list:\n",
        "        x = torch.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "        temp.append(torch.mean(x, dim=0).squeeze(0))\n",
        "    return torch.stack(temp).to(temp[0].device)\n",
        "\n",
        "class DetectorModule(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_dim,\n",
        "        hidden_dim,\n",
        "        output_dim,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "        self.mix_logits = nn.Parameter(torch.zeros(4))\n",
        "\n",
        "    def forward(self, qa_embedding, qa_gradient, ia_embedding, ia_gradient):\n",
        "        qa_embedding = get_mean(qa_embedding)\n",
        "        qa_gradient = get_mean(qa_gradient)\n",
        "        ia_embedding = get_mean(ia_embedding)\n",
        "        ia_gradient = get_mean(ia_gradient)\n",
        "\n",
        "        weights = torch.softmax(self.mix_logits, dim=0)\n",
        "\n",
        "        x = (\n",
        "            weights[0] * qa_embedding +\n",
        "            weights[1] * qa_gradient +\n",
        "            weights[2] * ia_embedding +\n",
        "            weights[3] * ia_gradient)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "id": "67b4e544a0644a9d"
    },
    {
      "metadata": {
        "id": "3fee4df5d23d31e0"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "class HallucinationDataset(Dataset):\n",
        "    def __init__(self, qa_embeddings, qa_gradients, ia_embeddings, ia_gradients, labels):\n",
        "        self.qa_embeddings = qa_embeddings\n",
        "        self.qa_gradients = qa_gradients\n",
        "        self.ia_embeddings = ia_embeddings\n",
        "        self.ia_gradients = ia_gradients\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.qa_embeddings[idx], self.qa_gradients[idx], self.ia_embeddings[idx], self.ia_gradients[idx], self.labels[idx]\n",
        "\n",
        "\n",
        "def hallucination_collate_fn(batch):\n",
        "    qa_embeddings = []\n",
        "    qa_gradients = []\n",
        "    ia_embeddings = []\n",
        "    ia_gradients = []\n",
        "    labels = []\n",
        "\n",
        "    for sample in batch:\n",
        "        qa_embeddings.append(sample[0])\n",
        "        qa_gradients.append(sample[1])\n",
        "        ia_embeddings.append(sample[2])\n",
        "        ia_gradients.append(sample[3])\n",
        "        labels.append(sample[4])\n",
        "    return qa_embeddings, qa_gradients, ia_embeddings, ia_gradients, torch.tensor(labels)\n",
        "\n",
        "def load_egh_dataset(folder_path) -> list:\n",
        "    dataset_path = folder_path + '/dataset.json'\n",
        "    images_path = folder_path + '/images/'\n",
        "    dataset = []\n",
        "\n",
        "    with open(dataset_path, 'r') as f:\n",
        "        data_list = json.load(f)\n",
        "    for data in data_list:\n",
        "        dataset.append({\n",
        "            \"id\": data['id'],\n",
        "            \"image_path\": images_path + data['image_id'],\n",
        "            \"query\": data['query'],\n",
        "            \"answer\": data['answer'],\n",
        "            \"label\": data['label']\n",
        "        })\n",
        "    print(f\"Successfully load the EHG dataset with: {len(dataset)} samples.\")\n",
        "    return dataset"
      ],
      "id": "3fee4df5d23d31e0"
    },
    {
      "metadata": {
        "id": "49a8769ceeee9e83"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "def train(detector, loss_function, optimizer, data_loader):\n",
        "    total_loss = 0\n",
        "\n",
        "    for _, batch in enumerate(data_loader):\n",
        "        optimizer.zero_grad()\n",
        "        qa_embedding, qa_gradient, ia_embedding, ia_gradient, label = batch\n",
        "        label = label.float()\n",
        "        output = detector(qa_embedding, qa_gradient, ia_embedding, ia_gradient).squeeze()\n",
        "        loss = loss_function(output, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss\n",
        "    return total_loss\n",
        "\n",
        "def eval_detector(detector, data_loader):\n",
        "    total_label, total_pred, total_out = [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _, batch in enumerate(data_loader):\n",
        "            qa_embedding, qa_gradient, ia_embedding, ia_gradient, label = batch\n",
        "\n",
        "            output = detector(qa_embedding, qa_gradient, ia_embedding, ia_gradient).squeeze()\n",
        "            total_out += output.tolist()\n",
        "            total_label += label.tolist()\n",
        "            pred = list(map(lambda x: round(x), output.tolist()))\n",
        "            total_pred += pred\n",
        "        f1 = f1_score(total_label, total_pred, average='macro')\n",
        "        acc = accuracy_score(total_label, total_pred)\n",
        "        precision, recall, cm = precision_recall_curve(total_label, total_pred)\n",
        "        pr_auc = auc(recall, precision)\n",
        "    return acc, f1, pr_auc\n",
        "\n",
        "def load_dataset(dir_path, model, processor, device):\n",
        "    data_list = load_egh_dataset(dir_path)\n",
        "    qa_embedding, qa_gradient, ia_embedding, ia_gradient = (\n",
        "        batch_extract_features(data_list, model, processor, device))\n",
        "    labels = [data['label'] for data in data_list]\n",
        "    hidden_size = qa_embedding[0].size(-1)\n",
        "    return HallucinationDataset(\n",
        "        qa_embedding,\n",
        "        qa_gradient,\n",
        "        ia_embedding,\n",
        "        ia_gradient,\n",
        "        labels,\n",
        "    ), hidden_size"
      ],
      "id": "49a8769ceeee9e83"
    },
    {
      "metadata": {
        "id": "8384363e755a4444"
      },
      "cell_type": "markdown",
      "source": [
        "#### Training"
      ],
      "id": "8384363e755a4444"
    },
    {
      "metadata": {
        "id": "d713074a30ee6d06"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--dataset_dir_path\", type=str, default=\"egh_vlm\")\n",
        "parser.add_argument(\"--model_name\", type=str, default=\"Qwen/Qwen3-VL-2B-Instruct\")\n",
        "parser.add_argument(\"--train_ratio\", type=float, default=0.5)\n",
        "args, _ = parser.parse_known_args()\n",
        "\n",
        "# VLM model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Qwen3VLForConditionalGeneration.from_pretrained(\n",
        "    args.model_name,\n",
        "    dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "processor = AutoProcessor.from_pretrained(args.model_name)"
      ],
      "id": "d713074a30ee6d06"
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1b9234894b80f63",
        "outputId": "eb451bc5-3014-46e1-f905-eb765cf28020"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully load the EHG dataset with: 10 samples.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extract features:: 100%|██████████| 10/10 [01:33<00:00,  9.31s/it]\n"
          ]
        }
      ],
      "execution_count": null,
      "source": [
        "# Dataset\n",
        "dataset, hidden_size = load_dataset(args.dataset_dir_path, model, processor, device)\n",
        "train_dataset = dataset\n",
        "test_dataset = dataset\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=16,\n",
        "    collate_fn=hallucination_collate_fn,\n",
        "    shuffle=True,\n",
        ")\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=16,\n",
        "    collate_fn=hallucination_collate_fn,\n",
        "    shuffle=True,\n",
        ")"
      ],
      "id": "a1b9234894b80f63"
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f6d130290b13541",
        "outputId": "32f5283c-d369-46f6-b59a-203ccc3f9908"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.0004\n",
            "Epoch [1/10], ACC: 0.0000, F1: 0.0000, PR-AUC:0.8944\n",
            "Epoch [2/10], Loss: 0.0017\n",
            "Epoch [2/10], ACC: 0.1000, F1: 0.0571, PR-AUC:0.8944\n",
            "Best ACC at epoch 11\n",
            "Best F1 at epoch 11\n",
            "Epoch [3/10], Loss: 0.0005\n",
            "Epoch [3/10], ACC: 0.0000, F1: 0.0000, PR-AUC:0.8903\n",
            "Epoch [4/10], Loss: 0.0005\n",
            "Epoch [4/10], ACC: 0.0000, F1: 0.0000, PR-AUC:0.8667\n",
            "Epoch [5/10], Loss: 0.0008\n",
            "Epoch [5/10], ACC: 0.0000, F1: 0.0000, PR-AUC:0.9083\n",
            "Epoch [6/10], Loss: 0.0006\n",
            "Epoch [6/10], ACC: 0.4000, F1: 0.1944, PR-AUC:0.9262\n",
            "Best ACC at epoch 11\n",
            "Best F1 at epoch 11\n",
            "Epoch [7/10], Loss: 0.0003\n",
            "Epoch [7/10], ACC: 0.0000, F1: 0.0000, PR-AUC:0.9262\n",
            "Epoch [8/10], Loss: 0.0003\n",
            "Epoch [8/10], ACC: 0.1000, F1: 0.0357, PR-AUC:0.9181\n",
            "Epoch [9/10], Loss: 0.0003\n",
            "Epoch [9/10], ACC: 0.2000, F1: 0.1238, PR-AUC:0.9262\n",
            "Epoch [10/10], Loss: 0.0004\n",
            "Epoch [10/10], ACC: 0.2000, F1: 0.1032, PR-AUC:0.9262\n",
            "Training Finished!\n"
          ]
        }
      ],
      "execution_count": null,
      "source": [
        "# Training\n",
        "detector = DetectorModule(hidden_size, hidden_size, 1)\n",
        "epoch = 10\n",
        "loss_function = nn.BCEWithLogitsLoss()\n",
        "optim = torch.optim.Adam(detector.parameters(), lr=1e-4)\n",
        "best_acc = 0.0\n",
        "best_f1 = 0.0\n",
        "\n",
        "for i in range(epoch):\n",
        "    total_loss = train(detector, loss_function, optim, train_dataloader)\n",
        "    print(f'Epoch [{i + 1}/{epoch}], Loss: {total_loss / 2000:.4f}')\n",
        "    acc, f1, pr_auc = eval_detector(detector, test_dataloader)\n",
        "    print(f'Epoch [{i + 1}/{epoch}], ACC: {acc:.4f}, F1: {f1:.4f}, PR-AUC:{pr_auc:.4f}')\n",
        "\n",
        "    if acc > best_acc:\n",
        "        best_acc = acc\n",
        "        print(f'Best ACC at epoch {epoch + 1}')\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        print(f'Best F1 at epoch {epoch + 1}')\n",
        "\n",
        "    if total_loss < 1e-5:\n",
        "        break\n",
        "\n",
        "print(f'Training Finished!')"
      ],
      "id": "1f6d130290b13541"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NtHzem52eLbD"
      },
      "id": "NtHzem52eLbD",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}